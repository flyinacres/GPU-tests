{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9009fb4-c842-40bc-89a5-08c045f532a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'gemma_pytorch'...\n",
      "The syntax of the command is incorrect.\n",
      "mv: cannot stat '/kaggle/working/gemma_pytorch/gemma/*': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Setup the environment\n",
    "!pip install -q -U immutabledict sentencepiece \n",
    "!git clone https://github.com/google/gemma_pytorch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00f54fc4-a0e0-44b2-8b0f-f8fa71257e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTRIBUTING.md\n",
      "LICENSE\n",
      "README.md\n",
      "docker\n",
      "gemma\n",
      "requirements.txt\n",
      "scripts\n",
      "setup.py\n",
      "tokenizer\n"
     ]
    }
   ],
   "source": [
    "!ls gemma_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5857c2d-7a0f-4763-9aff-511b0619db98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"gemma_pytorch\") \n",
    "from gemma.config import GemmaConfig, get_config_for_7b, get_config_for_2b\n",
    "from gemma.model import GemmaForCausalLM\n",
    "from gemma.tokenizer import Tokenizer\n",
    "import contextlib\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fed7249-5f31-4df9-ab7b-dc1a313bedd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ensure that this notebook is cuda-aware\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d74dec89-4ed7-4b08-bcd5-c196e5bfd851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.set_device(0)\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9df1cac0-06fb-40ca-bdfc-950d1b4639cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1080 Ti'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ca82fd5-3a5a-43f4-bb51-754ab15896d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "VARIANT = \"2b-it\" \n",
    "# Need to set this to cuda, not gpu or cpu while using the gpu t4 on kaggle.\n",
    "# Much faster results (as expected) when I did so.\n",
    "MACHINE_TYPE = \"cuda\" \n",
    "weights_dir = 'gemma_pytorch\\\\tokenizer' \n",
    "\n",
    "@contextlib.contextmanager\n",
    "def _set_default_tensor_type(dtype: torch.dtype):\n",
    "  \"\"\"Sets the default torch dtype to the given dtype.\"\"\"\n",
    "  torch.set_default_dtype(dtype)\n",
    "  yield\n",
    "  torch.set_default_dtype(torch.float)\n",
    "\n",
    "model_config = get_config_for_2b() if \"2b\" in VARIANT else get_config_for_7b()\n",
    "model_config.tokenizer = os.path.join(weights_dir, \"tokenizer.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67d86cd2-8f5c-4960-b7aa-1f16b498ac62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GemmaConfig(vocab_size=256000, max_position_embeddings=8192, num_hidden_layers=18, num_attention_heads=8, num_key_value_heads=1, hidden_size=2048, intermediate_size=16384, head_dim=256, rms_norm_eps=1e-06, dtype='bfloat16', quant=False, tokenizer='gemma_pytorch\\\\tokenizer\\\\tokenizer.model')\n"
     ]
    }
   ],
   "source": [
    "print(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce36603d-2b8e-420a-80d0-9d497cdb5419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Dev\\anaconda\\envs\\cuda_test\\Lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(MACHINE_TYPE)\n",
    "with _set_default_tensor_type(model_config.get_dtype()):\n",
    "  model = GemmaForCausalLM(model_config)\n",
    "  ckpt_path = os.path.join(weights_dir, f'gemma-{VARIANT}.ckpt')\n",
    "  model.load_weights(ckpt_path)\n",
    "  model = model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4ca7bb0-70ac-4d4b-b65b-a3d03176f803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Proper Dead Lift Form**\\n\\n* Keep your back straight and your body in a neutral position.\\n* Use a barbell that is appropriate for your body weight.\\n* Press the barbell up until your arms are completely locked out.\\n* Squeeze your glutes and hamstrings to return the barbell to the ground.\\n\\n**Concerns with Dead Lift Form**\\n\\n* **Poor posture:** Slouching or hunching over causes the spine to round, increasing the risk of injury.\\n* **Not using enough weight:** Using too light of a weight makes it difficult to perform the exercise correctly.\\n* **Not keeping your back straight:** A stiff back makes it easier for the barbell to come down too quickly, resulting in injury.\\n* **Using too much weight:** Lifting too heavy can damage your muscles and joints.\\n* **Not gripping the barbell properly:** Using a grip that is too wide or too narrow can cause the barbell to slide out of your hands and drop.\\n* **Allowing the barbell to swing back too far:** This can cause overtraining and muscle damage.\\n* **Not bending your knees:** Keeping your knees slightly bent helps to protect your lower back.\\n* **Exceeding your limits:** Dead lifting too often or too heavy can cause muscle tears and other injuries.\\n* **Using poor form for multiple exercises:** Switching between different exercises without warming up properly can lead to muscle imbalances and injuries.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the model\n",
    "\n",
    "USER_CHAT_TEMPLATE = \"<start_of_turn>user\\n{prompt}<end_of_turn>\\n\"\n",
    "MODEL_CHAT_TEMPLATE = \"<start_of_turn>model\\n{prompt}<end_of_turn>\\n\"\n",
    "\n",
    "prompt = (\n",
    "    USER_CHAT_TEMPLATE.format(\n",
    "        prompt=\"Produce a check list of proper dead lift form and concerns\"\n",
    "    )\n",
    "    + \"<start_of_turn>model\\n\"\n",
    ")\n",
    "\n",
    "model.generate(\n",
    "    prompt,\n",
    "    device=device,\n",
    "    output_len=300,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cuda)",
   "language": "python",
   "name": "cuda_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
